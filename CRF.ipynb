{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(), \n",
    "                                                           s['POS'].values.tolist(), \n",
    "                                                           s['Tag'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('Sentence #').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X,y,testset_size=0.3):\n",
    "    \"\"\"Split train-test data\"\"\" \n",
    "    return train_test_split(X, y, test_size=testset_size, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    # Create CRF model\n",
    "    crf = sklearn_crfsuite.CRF(\n",
    "        algorithm='lbfgs',\n",
    "        c1=0.1,\n",
    "        c2=0.1,\n",
    "        max_iterations=100,\n",
    "        all_possible_transitions=True\n",
    "    )\n",
    "\n",
    "    # Fit CRF model\n",
    "    crf.fit(X_train, y_train)\n",
    "    \n",
    "    return crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(y_test, y_pred,avg='weighted'):\n",
    "    \"\"\"evaluate model performance\"\"\"\n",
    "    accuracy=metrics.flat_f1_score(y_test, y_pred, average=avg)\n",
    "    precison=metrics.flat_precision_score(y_test, y_pred, average=avg)\n",
    "    recall=metrics.flat_recall_score(y_test, y_pred, average=avg)\n",
    "    f1score=metrics.flat_f1_score(y_test, y_pred, average=avg)\n",
    "    return {\"accuracy\":accuracy, \"precison\":precison, \"recall\":recall, \"f1score\":f1score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('ner_dataset.csv', encoding = \"ISO-8859-1\")\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Sentence\n",
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences\n",
    "\n",
    "# get features and labels\n",
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47959"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = split_data(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf=train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9353594409301975,\n",
       " 'precison': 0.9365881697278384,\n",
       " 'recall': 0.9373088685015291,\n",
       " 'f1score': 0.9353594409301975}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the labels\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "# evaluate the performance\n",
    "evaluate_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = [(word2features(s, i)) for i in range(len(s)) for s in sentences]\n",
    "y = [s for s in sent2labels(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features=pd.DataFrame(X_features)\n",
    "X_features_list=df_features.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Tag', axis=1)\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X = dv.fit_transform(X[:100].to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>word.lower()</th>\n",
       "      <th>word[-3:]</th>\n",
       "      <th>word[-2:]</th>\n",
       "      <th>word.isupper()</th>\n",
       "      <th>word.istitle()</th>\n",
       "      <th>word.isdigit()</th>\n",
       "      <th>postag</th>\n",
       "      <th>postag[:2]</th>\n",
       "      <th>BOS</th>\n",
       "      <th>EOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>thousands</td>\n",
       "      <td>nds</td>\n",
       "      <td>ds</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>iranian</td>\n",
       "      <td>ian</td>\n",
       "      <td>an</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>helicopter</td>\n",
       "      <td>ter</td>\n",
       "      <td>er</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>they</td>\n",
       "      <td>hey</td>\n",
       "      <td>ey</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PR</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>u.n.</td>\n",
       "      <td>.N.</td>\n",
       "      <td>N.</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47954</th>\n",
       "      <td>1.0</td>\n",
       "      <td>opposition</td>\n",
       "      <td>ion</td>\n",
       "      <td>on</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47955</th>\n",
       "      <td>1.0</td>\n",
       "      <td>on</td>\n",
       "      <td>On</td>\n",
       "      <td>On</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47956</th>\n",
       "      <td>1.0</td>\n",
       "      <td>following</td>\n",
       "      <td>ing</td>\n",
       "      <td>ng</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VB</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47957</th>\n",
       "      <td>1.0</td>\n",
       "      <td>since</td>\n",
       "      <td>nce</td>\n",
       "      <td>ce</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47958</th>\n",
       "      <td>1.0</td>\n",
       "      <td>the</td>\n",
       "      <td>The</td>\n",
       "      <td>he</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47959 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias word.lower() word[-3:] word[-2:]  word.isupper()  word.istitle()  \\\n",
       "0       1.0    thousands       nds        ds           False            True   \n",
       "1       1.0      iranian       ian        an           False            True   \n",
       "2       1.0   helicopter       ter        er           False            True   \n",
       "3       1.0         they       hey        ey           False            True   \n",
       "4       1.0         u.n.       .N.        N.            True            True   \n",
       "...     ...          ...       ...       ...             ...             ...   \n",
       "47954   1.0   opposition       ion        on           False            True   \n",
       "47955   1.0           on        On        On           False            True   \n",
       "47956   1.0    following       ing        ng           False            True   \n",
       "47957   1.0        since       nce        ce           False            True   \n",
       "47958   1.0          the       The        he           False            True   \n",
       "\n",
       "       word.isdigit() postag postag[:2]   BOS   EOS  \n",
       "0               False    NNS         NN  True  True  \n",
       "1               False     JJ         JJ  True  True  \n",
       "2               False     NN         NN  True  True  \n",
       "3               False    PRP         PR  True  True  \n",
       "4               False    NNP         NN  True  True  \n",
       "...               ...    ...        ...   ...   ...  \n",
       "47954           False    NNP         NN  True  True  \n",
       "47955           False     IN         IN  True  True  \n",
       "47956           False    VBG         VB  True  True  \n",
       "47957           False     IN         IN  True  True  \n",
       "47958           False     DT         DT  True  True  \n",
       "\n",
       "[47959 rows x 11 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1-- Epoch 1\n",
      "\n",
      "-- Epoch 1\n",
      "-- Epoch 1-- Epoch 1\n",
      "-- Epoch 1\n",
      "\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 23.56, NNZs: 362, Bias: -3.000000, T: 7000, Avg. loss: 0.043429\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 1Norm: 8.83, NNZs: 69, Bias: -4.000000, T: 7000, Avg. loss: 0.004714\n",
      "Total training time: 0.13 seconds.\n",
      "\n",
      "-- Epoch 1\n",
      "Norm: 5.83, NNZs: 31, Bias: -2.000000, T: 7000, Avg. loss: 0.001857\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 5.29, NNZs: 20, Bias: -2.000000, T: 7000, Avg. loss: 0.001143\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.77, NNZs: 257, Bias: -5.000000, T: 7000, Avg. loss: 0.030000\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 26.57, NNZs: 384, Bias: -4.000000, T: 7000, Avg. loss: 0.041571\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.41, NNZs: 231, Bias: -3.000000, T: 7000, Avg. loss: 0.024000\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  17 | elapsed:    0.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  17 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  17 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  17 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  17 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  17 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Norm: 17.35, NNZs: 173, Bias: -3.000000, T: 7000, Avg. loss: 0.011857\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 7.42, NNZs: 49, Bias: -3.000000, T: 7000, Avg. loss: 0.002571\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 6.16, NNZs: 32, Bias: -2.000000, T: 7000, Avg. loss: 0.001571\n",
      "Total training time: 0.11 seconds.\n",
      "Norm: 8.77, NNZs: 74, Bias: -3.000000, T: 7000, Avg. loss: 0.006143\n",
      "Norm: 21.63, NNZs: 320, Bias: -4.000000, T: 7000, Avg. loss: 0.032857\n",
      "Total training time: 0.10 seconds.\n",
      "Total training time: 0.13 seconds.\n",
      "Norm: 18.38, NNZs: 232, Bias: -4.000000, T: 7000, Avg. loss: 0.026143\n",
      "Total training time: 0.10 seconds.\n",
      "Norm: 7.94, NNZs: 52, Bias: -3.000000, T: 7000, Avg. loss: 0.003714\n",
      "Total training time: 0.13 seconds.\n",
      "Norm: 3.16, NNZs: 10, Bias: -2.000000, T: 7000, Avg. loss: 0.000143\n",
      "Total training time: 0.11 seconds.\n",
      "Norm: 6.08, NNZs: 37, Bias: -3.000000, T: 7000, Avg. loss: 0.003286\n",
      "Total training time: 0.09 seconds.\n",
      "Norm: 24.21, NNZs: 352, Bias: 2.000000, T: 7000, Avg. loss: 0.033857\n",
      "Total training time: 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.41489255682524484,\n",
       " 'precison': 0.4251889733367007,\n",
       " 'recall': 0.417436974789916,\n",
       " 'f1score': 0.41489255682524484}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = df.fillna(method='ffill')\n",
    "df1=df[:10000]\n",
    "X = df1.drop('Tag', axis=1)\n",
    "y = df1.Tag.values\n",
    "classes=df1.Tag.unique()\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X = dv.fit_transform(X.to_dict('records'))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=0)\n",
    "\n",
    "per = Perceptron(verbose=10, n_jobs=-1, max_iter=5)\n",
    "per.partial_fit(X_train, y_train, classes)\n",
    "\n",
    "y_pred=per.predict(X_test)\n",
    "\n",
    "# evaluate the performance\n",
    "evaluate_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Sentence: 457</td>\n",
       "      <td>war</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Sentence: 457</td>\n",
       "      <td>crimes</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Sentence: 457</td>\n",
       "      <td>tribunal</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Sentence: 457</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Sentence: 457</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentence #      Word  POS Tag\n",
       "9995  Sentence: 457       war   NN   O\n",
       "9996  Sentence: 457    crimes  NNS   O\n",
       "9997  Sentence: 457  tribunal   NN   O\n",
       "9998  Sentence: 457        in   IN   O\n",
       "9999  Sentence: 457       The   DT   O"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.41489255682524484,\n",
       " 'precison': 0.4251889733367007,\n",
       " 'recall': 0.417436974789916,\n",
       " 'f1score': 0.41489255682524484}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "y_pred=per.predict(X_test)\n",
    "\n",
    "# evaluate the performance\n",
    "evaluate_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.41489255682524484,\n",
       " 'precison': 0.4251889733367007,\n",
       " 'recall': 0.417436974789916,\n",
       " 'f1score': 0.41489255682524484}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "pa =PassiveAggressiveClassifier()\n",
    "pa.fit(X_train, y_train)\n",
    "\n",
    "y_pred=per.predict(X_test)\n",
    "\n",
    "# evaluate the performance\n",
    "evaluate_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.41489255682524484,\n",
       " 'precison': 0.4251889733367007,\n",
       " 'recall': 0.417436974789916,\n",
       " 'f1score': 0.41489255682524484}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB(alpha=0.01)\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred=per.predict(X_test)\n",
    "\n",
    "# evaluate the performance\n",
    "evaluate_performance(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
